{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Scraping AlloCine**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Intro**\n",
    "\n",
    "In the current era, data collection and analysis are critical for extracting valuable insights from unstructured data such as web pages. Web scraping is a powerful technique that allows us to extract information from websites that may not be readily available in structured formats like APIs. In this project, we aim to scrape data from AlloCiné, a well-known French movie website, to gather information on 57 films. This project is important because it showcases how we can handle raw HTML content, clean it, and structure it into a dataframe for further analysis and machine learning applications.\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "- **Extract information** from a single HTML page to identify the patterns needed for scraping ([Step 1](#step-1-extract-information-from-a-single-page)).\n",
    "\n",
    "- **Loop through all locally stored pages**, extract the same information for each, and store the results in a dataframe ([Step 2](#step-2-loop-through-all-pages))\n",
    "\n",
    "⚠️ All HTML pages have been downloaded locally and can be found in the `Pages.rar` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step-by-Step Breakdown**\n",
    "\n",
    "### **Step 1: Extract Information from a Single Page**\n",
    "First, we import the necessary libraries such as `re` (for regular expressions) and `pandas` (for managing our data). We then load a sample HTML page from our local directory. This sample page will help us define the patterns needed to extract the required information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import html\n",
    "import os\n",
    "\n",
    "with open('Pages/Serie_435.html', 'r', encoding ='utf8') as output:\n",
    "    text=output.read()\n",
    "\n",
    "text = html.unescape(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the HTML page is read and cleaned using `html.unescape()` to remove any special characters specific to HTML formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Extracting Serie Informations**\n",
    "\n",
    "We use regular expressions to identify specific patterns in the HTML text, which allows us to extract key information like the title, period, duration, genre, director, and more. For instance, we extract the title of the movie using the following pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El barco']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title\n",
    "title_pattern = \"\"\"(?s)<meta name=\"robots\" content=\"index,follow,max-snippet:-1,max-image-preview:large\" />\\n        <title>(.*?) -\"\"\"\n",
    "\n",
    "title = re.findall(title_pattern, text)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statut\n",
    "status_pattern = \"\"\"(?s)<span class=\"ico-play-inner\"></span>\\n      <i class=\"ico-play-arrow\">\\n          <i class=\"arrow\"></i>\\n      </i>\\n  </span>\\n\\n\\n        \\n            \\n            \\n        \\n                <div class=\"label label-text label-sm label-danger-full label-status\">(.*?)</div>\"\"\"\n",
    "\n",
    "status = re.findall(status_pattern, text)\n",
    "if status:\n",
    "    status\n",
    "else:\n",
    "    status = [None]\n",
    "\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2011 - 2013']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Period\n",
    "period_pattern = \"\"\"(?s)<div class=\"meta  \">\\n        \\n        <div class=\"meta-body\">\\n                    <div class=\"meta-body-item meta-body-info\">\\n                                                                \\n                                                    \\n                                                    \\n                                                    \\n                                                \\n                (.*?)\\n                \\n                                <span class=\"spacer\">\"\"\"\n",
    "\n",
    "period = re.findall(period_pattern, text)\n",
    "period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duration\n",
    "duration_pattern = \"\"\"(?s)<span class=\"spacer\">/</span>\\n                \\n                                \\n                                    (.*?)min\\n                                \\n                                    <span class=\"spacer\">/</span>\"\"\"\n",
    "                                    \n",
    "duration= re.findall(duration_pattern, text)\n",
    "duration = [int(i) for i in duration]\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aventure']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The genre\n",
    "type_pattern = \"\"\"(?s)<span class=\"spacer\">/</span>\\n                \\n                                                                                                                                            <span class=\"ACrL3NACrl(.*?)</span>\"\"\"\n",
    "\n",
    "\n",
    "type = re.findall(type_pattern, text)\n",
    "\n",
    "type_cleaned = [re.search('>(.*)', item).group(1) for item in type] # tout ce qui vient après '>'\n",
    "type = type_cleaned\n",
    "type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iván Escobar']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Director\n",
    "director_pattern = \"\"\"(?s)<span class=\"light\">De</span>\\n                                                                                                \\n                                                                                    <a class=\"blue-link\" href=\"/personne/fichepersonne_gen_cpersonne=(.*?)</a>\"\"\"\n",
    "                                                                              \n",
    "director = re.findall(director_pattern, text)\n",
    "director_cleaned = [re.search('>(.*)', item).group(1) for item in director]\n",
    "director = [', '.join(director_cleaned)]\n",
    "director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mario Casas']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main charater\n",
    "main_character_pattern = \"\"\"(?s)<span class=\"light\">Avec</span>\\n                \\n                                                                                                                                    \\n                                                                                    <span class=\"ACrL3BACrl(.*?)</span>\"\"\"\n",
    "                                                                                    \n",
    "main_character = re.findall(main_character_pattern, text)\n",
    "main_character_cleaned = [re.search('>(.*)', item).group(1) for item in main_character]\n",
    "main_character = [', '.join(main_character_cleaned)]\n",
    "main_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Espagne']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nationality\n",
    "nationality_pattern = \"\"\"(?s)<span class=\"light\">Nationalité</span>\\n                                                <span class=\"ACrL3NA(.*?)</span>\\n                            </div>\"\"\"\n",
    "                                                                                    \n",
    "nationality = re.findall(nationality_pattern, text)\n",
    "nationality_cleaned = [re.search('> (.*)', item).group(1) for item in nationality]\n",
    "nationality = [', '.join(nationality_cleaned)]\n",
    "nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Antena 3']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The channel\n",
    "channel_pattern = \"\"\"<span class=\"light\">Chaîne d\\'origine</span> <span class=\"ACrL3NACrvY2ll(.*?) </span>\"\"\"\n",
    "\n",
    "channel = re.findall(channel_pattern, text)\n",
    "channel_cleaned = [re.search('> (.*)', item).group(1) for item in channel]\n",
    "channel = [', '.join(channel_cleaned)]\n",
    "channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None] [None]\n"
     ]
    }
   ],
   "source": [
    "# Ratings of press\n",
    "p_ratings_pattern = \"\"\"(?s)stareval-stars\"><div class=\"star icon\"></div><div class=\"star icon\"></div><div class=\"star icon\"></div><div class=\"star icon\"></div><div class=\"star icon\"></div></div><span class=\"stareval-note\">(.*?)</span><span class=\"stareval-review light\"> (.*?)</span></div>\\n        </div>\\n    </div>\\n    \\n            <div class=\"rating-item\">\\n                                    <div class=\"rating-item-content\">\\n                        <span class=\"ACrL3NACrl\"\"\"\n",
    "\n",
    "p_ratings = re.findall(p_ratings_pattern, text)\n",
    "if p_ratings:\n",
    "    note = [float(p_ratings[0][0].replace(',', '.'))]\n",
    "    critics = [int(re.findall(r'[0-9]+', p_ratings[0][1])[0])]\n",
    "else:\n",
    "    note = [None]\n",
    "    critics = [None]\n",
    "\n",
    "print(note, critics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.8]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings of public\n",
    "a_ratings_pattern = \"\"\"(?s)stareval-stars\"><div class=\"star icon\"></div><div class=\"star icon\"></div><div class=\"star icon\"></div><div class=\"star icon\"></div><div class=\"star icon\"></div></div><span class=\"stareval-note\">(.*?)</span><span class=\"stareval-review light\">\"\"\"\n",
    "\n",
    "a_ratings = re.findall(a_ratings_pattern, text)\n",
    "if a_ratings:\n",
    "    a_ratings = [float(val.replace(',', '.')) for val in a_ratings]\n",
    "    a_ratings = [a_ratings[0]]\n",
    "else:\n",
    "    a_ratings = [None]\n",
    "\n",
    "a_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # of episodes & seasons\n",
    "seasons_nb_pattern = \"\"\"(?s)<div class=\"stats-numbers-row stats-numbers-seriespage\">\\n                <div class=\"stats-numbers-row-item\">\\n            <div class=\"stats-number\">(.*?)</div>\\n            <div class=\"stats-info\">(.*?)</div>\\n        </div>\\n        \\n                <div class=\"stats-numbers-row-item\">\\n            <div class=\"stats-number\">(.*?)</div>\\n            <div class=\"stats-info\">Episode\"\"\"\n",
    "\n",
    "seasons_nb = re.findall(seasons_nb_pattern, text)\n",
    "if seasons_nb:\n",
    "    seasons_nb = [int(seasons_nb[0][0]), int(seasons_nb[0][2])]\n",
    "else:\n",
    "    seasons_nb = [None, None]\n",
    "seasons_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Film description (synopsis)\n",
    "desc_pattern = \"\"\"(?s)\\n    \"description\": \"(.*?)\"\\n\"\"\"\n",
    "\n",
    "desc = re.findall(desc_pattern, text)\n",
    "if desc:\n",
    "    desc\n",
    "else:\n",
    "    desc = [None]\n",
    "\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar patterns are used to extract other details such as the status of the show, period, duration, and director. After extracting all the information, we store it in a list `new_line`, which will be used to create a new row in a dataframe (Step 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El barco',\n",
       " None,\n",
       " '2011 - 2013',\n",
       " 75,\n",
       " 'Aventure',\n",
       " 'Iván Escobar',\n",
       " 'Mario Casas',\n",
       " 'Espagne',\n",
       " 'Antena 3',\n",
       " None,\n",
       " None,\n",
       " 3.8,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = [\n",
    "        title, status, period, duration, type, director, main_character, nationality,\n",
    "        channel, note, critics, a_ratings, seasons_nb, desc\n",
    "]\n",
    "\n",
    "new_line = []\n",
    "\n",
    "for sous_list in all:\n",
    "    for i in sous_list:\n",
    "        new_line.append(i)\n",
    "\n",
    "new_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Loop Through All Pages**\n",
    "Once we have successfully extracted data from a single page, we extend this process to all 57 pages stored locally in the 'Pages' directory. Using a `for` loop, we read each HTML file, extract the necessary information, and append it to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurel\\AppData\\Local\\Temp\\ipykernel_21016\\2900335162.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  film_data = pd.concat([film_data, temp], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>Statut</th>\n",
       "      <th>Période</th>\n",
       "      <th>Durée</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Réalisateur</th>\n",
       "      <th>Perso Principal</th>\n",
       "      <th>Nationalité</th>\n",
       "      <th>Chaîne</th>\n",
       "      <th>Note press</th>\n",
       "      <th>Critiques press</th>\n",
       "      <th>Note public</th>\n",
       "      <th>Saisons</th>\n",
       "      <th>Épisodes</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alphas</td>\n",
       "      <td>Annulée</td>\n",
       "      <td>2011 - 2012</td>\n",
       "      <td>42</td>\n",
       "      <td>Drame</td>\n",
       "      <td>Gail Berman</td>\n",
       "      <td>David Strathairn</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>SyFy US</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>Des personnes dotées de capacités neurologique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wolfblood</td>\n",
       "      <td>Annulée</td>\n",
       "      <td>2012 - 2017</td>\n",
       "      <td>26</td>\n",
       "      <td>Drame</td>\n",
       "      <td>Debbie Moon</td>\n",
       "      <td>Bobby Lockwood</td>\n",
       "      <td>Grande-Bretagne</td>\n",
       "      <td>CBBC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>Nouvel élève au lycée de Stoneybridge, Rhydian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Frankenstein Chronicles</td>\n",
       "      <td>Annulée</td>\n",
       "      <td>2015 - 2017</td>\n",
       "      <td>52</td>\n",
       "      <td>Drame</td>\n",
       "      <td>Benjamin Ross</td>\n",
       "      <td>Sean Bean</td>\n",
       "      <td>Grande-Bretagne</td>\n",
       "      <td>ITV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>Londres, 1827. Alors que la police fluviale de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Being Human (US)</td>\n",
       "      <td>Annulée</td>\n",
       "      <td>2011 - 2014</td>\n",
       "      <td>42</td>\n",
       "      <td>Drame</td>\n",
       "      <td>Jeremy Carver</td>\n",
       "      <td>Sam Witwer</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>SyFy US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>Trois colocataires âgés d'une trentaine d'anné...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Les Revenants</td>\n",
       "      <td>Terminée</td>\n",
       "      <td>2012 - 2015</td>\n",
       "      <td>52</td>\n",
       "      <td>Drame</td>\n",
       "      <td>Fabrice Gobert</td>\n",
       "      <td>Anne Consigny</td>\n",
       "      <td>France</td>\n",
       "      <td>Canal +</td>\n",
       "      <td>4.2</td>\n",
       "      <td>12</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>Dans une ville de montagne dominée par un giga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Titre    Statut      Période Durée  Genre  \\\n",
       "0                       Alphas   Annulée  2011 - 2012    42  Drame   \n",
       "1                    Wolfblood   Annulée  2012 - 2017    26  Drame   \n",
       "2  The Frankenstein Chronicles   Annulée  2015 - 2017    52  Drame   \n",
       "3             Being Human (US)   Annulée  2011 - 2014    42  Drame   \n",
       "4                Les Revenants  Terminée  2012 - 2015    52  Drame   \n",
       "\n",
       "      Réalisateur   Perso Principal      Nationalité   Chaîne  Note press  \\\n",
       "0     Gail Berman  David Strathairn           U.S.A.  SyFy US         3.9   \n",
       "1     Debbie Moon    Bobby Lockwood  Grande-Bretagne     CBBC         NaN   \n",
       "2   Benjamin Ross         Sean Bean  Grande-Bretagne      ITV         NaN   \n",
       "3   Jeremy Carver        Sam Witwer           U.S.A.  SyFy US         NaN   \n",
       "4  Fabrice Gobert     Anne Consigny           France  Canal +         4.2   \n",
       "\n",
       "  Critiques press  Note public Saisons Épisodes  \\\n",
       "0               7          3.9       2       24   \n",
       "1            None          4.0       5       62   \n",
       "2            None          4.0       2       12   \n",
       "3            None          3.9       4       52   \n",
       "4              12          4.2       2       16   \n",
       "\n",
       "                                         Description  \n",
       "0  Des personnes dotées de capacités neurologique...  \n",
       "1  Nouvel élève au lycée de Stoneybridge, Rhydian...  \n",
       "2  Londres, 1827. Alors que la police fluviale de...  \n",
       "3  Trois colocataires âgés d'une trentaine d'anné...  \n",
       "4  Dans une ville de montagne dominée par un giga...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colonnes = [\n",
    "    'Titre', 'Statut', 'Période', 'Durée', 'Genre', 'Réalisateur', 'Perso Principal', \n",
    "    'Nationalité', 'Chaîne', 'Note press', 'Critiques press', 'Note public', \n",
    "    'Saisons', 'Épisodes', 'Description'\n",
    "]\n",
    "\n",
    "film_data = pd.DataFrame(columns= colonnes)\n",
    "\n",
    "for page in os.listdir('Pages'):\n",
    "    file_path = 'Pages/{}'.format(page)\n",
    "    \n",
    "    with open(file_path,'r',encoding ='utf8') as output:\n",
    "        text = output.read()\n",
    "    \n",
    "    text = html.unescape(text)\n",
    "    \n",
    "    title_pattern = \"\"\"(?s)<meta name=\"robots\" content=\"index,follow,max-snippet:-1,max-image-preview:large\" />\\n        <title>(.*?) -\"\"\"\n",
    "    title = re.findall(title_pattern, text)\n",
    "\n",
    "\n",
    "    status_pattern = \"\"\"(?s)<span class=\"ico-play-inner\"></span>\\n      <i class=\"ico-play-arrow\">\\n          <i class=\"arrow\"></i>\\n      </i>\\n  </span>\\n\\n\\n        \\n            \\n            \\n        \\n                <div class=\"label label-text label-sm label-danger-full label-status\">(.*?)</div>\"\"\"\n",
    "    status = re.findall(status_pattern, text)\n",
    "    if status:\n",
    "        status\n",
    "    else:\n",
    "        status = [None]\n",
    "\n",
    "\n",
    "    period_pattern = \"\"\"(?s)<div class=\"meta  \">\\n        \\n        <div class=\"meta-body\">\\n                    <div class=\"meta-body-item meta-body-info\">\\n                                                                \\n                                                    \\n                                                    \\n                                                    \\n                                                \\n                (.*?)\\n                \\n                                <span class=\"spacer\">\"\"\"\n",
    "    period = re.findall(period_pattern, text)\n",
    "\n",
    "\n",
    "    duration_pattern = \"\"\"(?s)<span class=\"spacer\">/</span>\\n                \\n                                \\n                                    (.*?)min\\n                                \\n                                    <span class=\"spacer\">/</span>\"\"\"\n",
    "    duration= re.findall(duration_pattern, text)\n",
    "    duration = [int(i) for i in duration]\n",
    "\n",
    "\n",
    "    type_pattern = \"\"\"(?s)<span class=\"spacer\">/</span>\\n                \\n                                                                                                                                            <span class=\"ACrL3NACrl(.*?)</span>\"\"\"\n",
    "    type = re.findall(type_pattern, text)\n",
    "\n",
    "    type_cleaned = [re.search('>(.*)', item).group(1) for item in type] # tout ce qui vient après '>'\n",
    "    type = type_cleaned\n",
    "\n",
    "\n",
    "    director_pattern = \"\"\"(?s)<span class=\"light\">De</span>\\n                                                                                                \\n                                                                                    <a class=\"blue-link\" href=\"/personne/fichepersonne_gen_cpersonne=(.*?)</a>\"\"\"\n",
    "    director = re.findall(director_pattern, text)\n",
    "    director_cleaned = [re.search('>(.*)', item).group(1) for item in director]\n",
    "    director = [', '.join(director_cleaned)]\n",
    "\n",
    "\n",
    "    main_character_pattern = \"\"\"(?s)<span class=\"light\">Avec</span>\\n                \\n                                                                                                                                    \\n                                                                                    <span class=\"ACrL3BACrl(.*?)</span>\"\"\"\n",
    "    main_character = re.findall(main_character_pattern, text)\n",
    "    main_character_cleaned = [re.search('>(.*)', item).group(1) for item in main_character]\n",
    "    main_character = [', '.join(main_character_cleaned)]\n",
    "\n",
    "\n",
    "    nationality_pattern = \"\"\"(?s)<span class=\"light\">Nationalité</span>\\n                                                <span class=\"ACrL3NA(.*?)</span>\\n                            </div>\"\"\"\n",
    "    nationality = re.findall(nationality_pattern, text)\n",
    "    nationality_cleaned = [re.search('> (.*)', item).group(1) for item in nationality]\n",
    "    nationality = [', '.join(nationality_cleaned)]\n",
    "\n",
    "\n",
    "    channel_pattern = \"\"\"<span class=\"light\">Chaîne d\\'origine</span> <span class=\"ACrL3NACrvY2ll(.*?) </span>\"\"\"\n",
    "    channel = re.findall(channel_pattern, text)\n",
    "    channel_cleaned = [re.search('> (.*)', item).group(1) for item in channel]\n",
    "    channel = [', '.join(channel_cleaned)]\n",
    "\n",
    "\n",
    "    p_ratings_pattern = \"\"\"(?s)stareval-stars\"><div class=\"star icon\"></div><div class=\"star icon\"></div><div class=\"star icon\"></div><div class=\"star icon\"></div><div class=\"star icon\"></div></div><span class=\"stareval-note\">(.*?)</span><span class=\"stareval-review light\"> (.*?)</span></div>\\n        </div>\\n    </div>\\n    \\n            <div class=\"rating-item\">\\n                                    <div class=\"rating-item-content\">\\n                        <span class=\"ACrL3NACrl\"\"\"\n",
    "    p_ratings = re.findall(p_ratings_pattern, text)\n",
    "\n",
    "    if p_ratings:\n",
    "        note = [float(p_ratings[0][0].replace(',', '.'))]\n",
    "        critics = [int(re.findall(r'[0-9]+', p_ratings[0][1])[0])]\n",
    "    else:\n",
    "        note = [None]\n",
    "        critics = [None]\n",
    "\n",
    "\n",
    "    a_ratings_pattern = \"\"\"(?s)stareval-stars\"><div class=\"star icon\"></div><div class=\"star icon\"></div><div class=\"star icon\"></div><div class=\"star icon\"></div><div class=\"star icon\"></div></div><span class=\"stareval-note\">(.*?)</span><span class=\"stareval-review light\">\"\"\"\n",
    "    a_ratings = re.findall(a_ratings_pattern, text)\n",
    "    if a_ratings:\n",
    "        a_ratings = [float(val.replace(',', '.')) for val in a_ratings]\n",
    "        a_ratings = [a_ratings[0]]\n",
    "    else:\n",
    "        a_ratings = [None]\n",
    "\n",
    "\n",
    "    seasons_nb_pattern = \"\"\"(?s)<div class=\"stats-numbers-row stats-numbers-seriespage\">\\n                <div class=\"stats-numbers-row-item\">\\n            <div class=\"stats-number\">(.*?)</div>\\n            <div class=\"stats-info\">(.*?)</div>\\n        </div>\\n        \\n                <div class=\"stats-numbers-row-item\">\\n            <div class=\"stats-number\">(.*?)</div>\\n            <div class=\"stats-info\">Episode\"\"\"\n",
    "    seasons_nb = re.findall(seasons_nb_pattern, text)\n",
    "\n",
    "    if seasons_nb:\n",
    "        seasons_nb = [int(seasons_nb[0][0]), int(seasons_nb[0][2])]\n",
    "    else:\n",
    "        seasons_nb = [None, None]\n",
    "\n",
    "\n",
    "    desc_pattern = \"\"\"(?s)\\n    \"description\": \"(.*?)\"\\n\"\"\"\n",
    "    desc = re.findall(desc_pattern, text)\n",
    "    if desc:\n",
    "        desc\n",
    "    else:\n",
    "        desc = [None]\n",
    "\n",
    "\n",
    "    all = [title, status, period, duration, type, director, main_character, nationality,\n",
    "        channel, note, critics, a_ratings, seasons_nb, desc\n",
    "    ]\n",
    "\n",
    "    new_line = []\n",
    "\n",
    "    for sous_list in all:\n",
    "        for i in sous_list:\n",
    "            new_line.append(i)\n",
    "\n",
    "    temp = pd.DataFrame([new_line], columns= colonnes) # temporary df to store informations\n",
    "\n",
    "    film_data = pd.concat([film_data, temp], ignore_index=True)\n",
    "\n",
    "\n",
    "film_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each page is processed in a similar manner as in Step 1, and the extracted data is concatenated into the `film_data` dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Handling Missing Values**\n",
    "Some pages may not contain all the information, which could result in missing values (`NaN`). We handle these missing values appropriately, ensuring they don't affect our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Titre               0\n",
       "Statut             12\n",
       "Période             0\n",
       "Durée               0\n",
       "Genre               0\n",
       "Réalisateur         0\n",
       "Perso Principal     0\n",
       "Nationalité         0\n",
       "Chaîne              0\n",
       "Note press         32\n",
       "Critiques press    32\n",
       "Note public         0\n",
       "Saisons             1\n",
       "Épisodes            1\n",
       "Description         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line checks for any missing data in our dataframe, providing an overview of which columns contain `NaN` values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Saving the Data**\n",
    "Finally, we save the resulting dataframe to a csv file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super c'est parfait !\n"
     ]
    }
   ],
   "source": [
    "film_data.to_csv('film_data.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"Super c'est parfait !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
